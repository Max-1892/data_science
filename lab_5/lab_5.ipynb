{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 Lab - Data 101\n",
    "\n",
    "## Directions\n",
    "1. Show all work/steps/calculations. If it is easier to write it out by hand, do so and submit a scanned PDF in addition to this notebook. Otherwise, generate a Markdown cell for each answer.\n",
    "2. You must submit to **two** places by the deadline:\n",
    "    1. In the Lab section of the Course Module where you downloaded this file from, and\n",
    "    2. In your Lab Discussion Group, in the forum for the appropriate Module.\n",
    "    \n",
    "    (For this assignment, zip all 3 files: `Lab - Module 5.ipynb`, `hurricanes.py` and `hurricane.db` up before submitting to either place).\n",
    "    \n",
    "3. You may use any core Python libraries or Numpy/Scipy. **Additionally, code from the Module notebooks and lectures is fair to use and modify.** You may also consult Stackoverflow (SO). If you use something from SO, please place a comment with the URL to document the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and Storing Data\n",
    "\n",
    "This lab is a test of your data munging skills. There is an individual part (that you should do by Thursday) and a group part although everything is up for discussion.\n",
    "\n",
    "### Basic Outline\n",
    "\n",
    "1. Using curl or wget obtain a local copy of the following web page: Atlantic Hurricane Season (https://en.wikipedia.org/wiki/Atlantic_hurricane_season).\n",
    "2. Using Beautiful Soup 4 and Python, parse the HTML file into a useable dataset.\n",
    "3. Write this data set to a SQLite3 database called `hurricanes.db`\n",
    "4. Run some queries against the data set.\n",
    "\n",
    "### Details\n",
    "\n",
    "The data is contained in many separate tables. The challenge is to write a general table parsing function and then locate each table and apply the function to it. You only need to get the data from the tables starting at 1850s. Not all years have the same data. You only need to save the following columns. The name is parentheses is the name the column should have in the database table.\n",
    "\n",
    "Year (year)\n",
    "Number of tropical storms (tropical_storms)\n",
    "Number of hurricanes (hurricanes)\n",
    "Number of Major Hurricanes (major_hurricanes)\n",
    "Deaths (deaths)\n",
    "Damage (damage)\n",
    "Notes (notes)\n",
    "\n",
    "Note that \"Damage\" doesn't start until 1900s and \"Notes\" was added in 1880s. \"Strongest Storm\" should be added to the Notes column (even in years that didn't have Notes) as should \"Retired Storms\". The name of the database table should be atlantic_hurricanes. The name of the table file (SQLite3 uses a file) should be hurricanes.db (who knows...you might need to add Pacific storms someday).\n",
    "\n",
    "There are a number of parsing problems which will most likely require regular expressions. First, the Deaths column has numbers that include commas and entries that are not numbers (Unknown and None). How should you code Unknown and None so that answers are not misleading but queries are still fairly straightforward to write?\n",
    "\n",
    "Similarly, Damages has numbers with commas, currency signs and different amount words (millions, billions). How will you normalize all of these so that a query can compare them?\n",
    "\n",
    "Additionally, the way that Tropical Storms are accounted for seems to change mysteriously. Looking over the data, it's not immediately apparent when the interpretation should change. 1850s, 1860s definitely but 1870s? Not sure. It could just be a coincidence that there were never more hurricanes than tropical storms which seems to be the norm but see, for example, 1975. Welcome to Data Science!\n",
    "\n",
    "You should put your parsing code in `hurricanes.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries\n",
    "\n",
    "When you are done, you must write and execute 5 queries against your database. Those queries should be run from this notebook. Find the documentation for using SQLite3 from Python (the library is already included).\n",
    "\n",
    "1\\. What year had the most tropical storms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. What year had the most major hurricanes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. What year had the most deaths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. What year had the most damage (not inflation adjusted)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. What year had the highest proportion of tropical storms turn into major hurricanes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Create a query of your own to have your group answer. Post it along with your file (so people don't have to download your zip file to read it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Discussion\n",
    "\n",
    "1. Answer one member's #6 query.\n",
    "2. What is the granularity of this data? (Are the rows the most specific observation possible?)\n",
    "3. Each section links to details about each hurrican season. Review each Season's page and discussion strategies for extracting the information for every hurricane."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
